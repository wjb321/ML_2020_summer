{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm investigation is a good method to find the suitable algorithm in machine learning. so investigation in the begining we dont konw\n",
    "which algorithm is suitable, so we need design a experiment to investigate and check.  \n",
    "1)how to investigate classification algorithm in machine learning  \n",
    "2)how to investigate 2 linear classification algorithms.  \n",
    "3)how to invertigate 4 different non-linear classification algorithms  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)algorithm investigation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before investigation, we dont know which algorithms are suitble or efficient to build optimal model. so we need series of experiements to make sure. the process named **algorithm investigation.** we always use same data to test different algorithms and see the results, which one is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2）algorithm sketch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1）linear algorithm:** logisticRegression(), LDA()  \n",
    "we assume both algorithms need gaussian data as input.  \n",
    "高斯分布的容错性最好，如果不服从高斯分布，那么分类可能不是无偏的，会出现部分数据分类误差很大，部分数据分类误差很小的情况。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n",
      "mean result 0.772\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, cross_val_score #, LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "filename ='/Users/wangjiabin/ML_2020_summer/<ml with python practice>/cha_7_data_visibility/pima_data.csv'\n",
    "columns =['Pregnancies', 'Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
    "dataset = read_csv(filename)\n",
    "array = dataset.values\n",
    "#print(array.shape)\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "num_folds = 10\n",
    "seed =7\n",
    "kfold = KFold(n_splits =num_folds,shuffle =True, random_state =seed)\n",
    "model = LogisticRegression(solver='lbfgs',max_iter=999)\n",
    "result = cross_val_score(model, X,Y, cv =kfold)\n",
    "print('mean result %.3f'% result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean result 0.767\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "kfold = KFold(n_splits =num_folds,shuffle =True, random_state =seed)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "result = cross_val_score(model, X,Y, cv =kfold)\n",
    "print('mean result %.3f'% result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2) non_linear:** k_near_neighbor,bayesian, classification and regression tree, SVM   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1746170936260829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "result = cross_val_score(model, X,Y,cv = kfold, scoring= scoring)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7591421736158578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "result = cross_val_score(model,X,Y,cv=kfold)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6941216678058784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "result = cross_val_score(model, X,Y,cv= kfold)\n",
    "print(result.mean())\n",
    "#第16章节有一个baggingclassifier()可以对比效果值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760457963089542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "result = cross_val_score(model, X,Y,cv = kfold)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
